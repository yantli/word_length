print(proportion)
return(proportion)
}
# 3)
Finnish = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
Uyghur = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/uyghur.txt",
c("ü", "ö", "e"),
c("u", "o", "a"))
print(Finnish > Uyghur)
a <- c('hello','world')
b <- paste(a, collapse = '')
b
'.*[{b}].*[{b}]'
library(tidyverse)
# method using regex
get_cooccurrence_tokens2 <- function(corpus, set1, set2) {
data = read_csv(corpus, col_names = FALSE)
set_1 <- paste(set1, collapse = '')
set_2 <- paste(set2, collapse = '')
regex1 <- str_glue('.*[{set_1}].*[{set_2}].*')
regex2 <- str_glue('.*[{set_2}].*[{set_1}].*')
roots <- unique(c(str_subset(data$X1, regex1), str_subset(data$X1, regex2)))
return(roots)
}
# 3)
Finnish = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
# 2)
get_cooccurrence_proportion <- function(corpus, set1, set2){
data = read_csv(corpus, col_names = FALSE)
num_of_roots = length(data$X1)
num_of_disharm_roots = length(get_cooccurrence_tokens2(corpus, set1, set2))
proportion = num_of_disharm_roots / num_of_roots
return(proportion)
}
# 3)
Finnish = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
Uyghur = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/uyghur.txt",
c("ü", "ö", "e"),
c("u", "o", "a"))
print(Finnish > Uyghur)
# method using regex
get_cooccurrence_tokens2 <- function(corpus, set1, set2) {
data = read_csv(corpus, col_names = FALSE)
set_1 <- paste(set1, collapse = '')
set_2 <- paste(set2, collapse = '')
regex1 <- str_glue('^.*[{set_1}].*[{set_2}].*$')
regex2 <- str_glue('^.*[{set_2}].*[{set_1}].*$')
roots <- unique(c(str_subset(data$X1, regex1), str_subset(data$X1, regex2)))
return(roots)
}
# 2)
get_cooccurrence_proportion <- function(corpus, set1, set2){
data = read_csv(corpus, col_names = FALSE)
num_of_roots = length(data$X1)
num_of_disharm_roots = length(get_cooccurrence_tokens2(corpus, set1, set2))
proportion = num_of_disharm_roots / num_of_roots
return(proportion)
}
# 3)
Finnish = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
Uyghur = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/uyghur.txt",
c("ü", "ö", "e"),
c("u", "o", "a"))
print(Finnish)
print(Uyghur)
# method using regex
get_cooccurrence_tokens2 <- function(corpus, set1, set2) {
data = read_csv(corpus, col_names = FALSE)
set_1 <- paste(set1, collapse = '')
set_2 <- paste(set2, collapse = '')
regex1 = '.*[{set_1}].*[{set_2}].*'
regex2 = '.*[{set_2}].*[{set_1}].*'
roots <- unique(c(str_subset(data$X1, regex1), str_subset(data$X1, regex2)))
return(roots)
}
# 2)
get_cooccurrence_proportion <- function(corpus, set1, set2){
data = read_csv(corpus, col_names = FALSE)
num_of_roots = length(data$X1)
num_of_disharm_roots = length(get_cooccurrence_tokens2(corpus, set1, set2))
proportion = num_of_disharm_roots / num_of_roots
return(proportion)
}
# 3)
Finnish = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
Uyghur = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/uyghur.txt",
c("ü", "ö", "e"),
c("u", "o", "a"))
print(Finnish)
print(Uyghur)
b
re = '.*[{b}].*'
str_view('dafioahelloworld', re)
re = str_glue('.*[{b}].*')
str_view('dafioahelloworld', re)
iris
sepallength <- as.list(iris)
sepallength
print(Uyghur)
print(Finnish)
# method using regex
get_cooccurrence_tokens2 <- function(corpus, set1, set2) {
data = read_csv(corpus, col_names = FALSE)
set_1 <- paste(set1, collapse = '')
set_2 <- paste(set2, collapse = '')
regex1 <- str_glue('.*[{set_1}].*[{set_2}].*')
regex2 <- str_glue('.*[{set_2}].*[{set_1}].*')
roots <- unique(c(str_subset(data$X1, regex1), str_subset(data$X1, regex2)))
return(roots)
}
# 2)
get_cooccurrence_proportion <- function(corpus, set1, set2){
data = read_csv(corpus, col_names = FALSE)
num_of_roots = length(data$X1)
num_of_disharm_roots = length(get_cooccurrence_tokens2(corpus, set1, set2))
proportion = num_of_disharm_roots / num_of_roots
return(proportion)
}
# 3)
Finnish = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
Uyghur = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/uyghur.txt",
c("ü", "ö", "e"),
c("u", "o", "a"))
library(tidyverse)
# 3)
Finnish_prop = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
Uyghur_prop = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/uyghur.txt",
c("ü", "ö", "e"),
c("u", "o", "a"))
print(Finnish_prop)
print(Uyghur_prop)
#4.
#1) old method without using regex
get_cooccurrence_tokens <- function(corpus, set1, set2) {
root_list <- c()
data = read.table(corpus, header = FALSE)[[1]]
for (root in data) {
for (element in set1) {
if(isTRUE(str_detect(root, element))) {
for (element in set2) {
if (isTRUE(str_detect(root, element))) {
if (isFALSE(root %in% root_list)) {
root_list <- append(root_list, root)
}
}
}
}
}
}
return(root_list)
}
# 2)
get_cooccurrence_proportion <- function(corpus, set1, set2){
data = read_csv(corpus, col_names = FALSE)
num_of_roots = length(data$X1)
num_of_disharm_roots = length(get_cooccurrence_tokens(corpus, set1, set2))
proportion = num_of_disharm_roots / num_of_roots
return(proportion)
}
# 3)
Finnish_prop = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
Uyghur_prop = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/uyghur.txt",
c("ü", "ö", "e"),
c("u", "o", "a"))
print(Finnish_prop)
print(Uyghur_prop)
Uyghur_token = get_cooccurrence_tokens2("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/uyghur.txt",
c("ü", "ö", "e"),
c("u", "o", "a"))
print(length(Uyghur_token))
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
bodymass = read.csv("./bodymass.csv",header=TRUE)
head(bodymass)
head(bodymass)
plot(body$height, body$bodymass, xlab="Height", ylab="Bodymass", main="Scatterplot")
body = read.csv("./bodymass.csv",header=TRUE)
head(body)
plot(body$height, body$bodymass, xlab="Height", ylab="Bodymass", main="Scatterplot")
abline(lm(bodymass~height, data=body))
plot(body$height, body$bodymass, xlab="Height", ylab="Bodymass", main="Scatterplot")
abline(lm(bodymass~height, data=body))
abline(lm(bodymass~height, data = body))
plot(abline(lm(bodymass~height, data = body)))
####################################
# Import alcoholarm dataset
treadwear = read.table("./treadwear.txt" , header=TRUE)
plot(body$height, body$bodymass, xlab = "Height", ylab = "Bodymass", main = "Scatterplot")
abline(lm(bodymass~height, data = body))
model <- lm(bodymass~height, data = body)
summary(model)
plot(model)
qqnorm(rstandard(model))
plot(model)
model2 <- lm(bodymass~height + I(height^2), data = body)
summary(model2)
anova(model, model2)
plot(model2)
reduced_model <- lm(bodymass ~ 1, data = body)
anova(reduced_model, model2)
bodymass = 160.727653 - 2.075533 * 170 + 0.009104 * 170^2
bodymass
bodymass1
bodymass1 = 160.727653 - 2.075533 * 170 + 0.009104 * 170^2
bodymass2 = 160.727653 - 2.075533 * 171 + 0.009104 * 171^2
bodymass2
difference <- bodymass2 - bodymass1
difference
bodymass3 = 160.727653 - 2.075533 * 175 + 0.009104 * 175^2
bodymass3
difference2 <- bodymass3 - bodymass1
difference2
physical = read.txt("./PhysicalData.txt",header=TRUE)
physical = read.table("./PhysicalData.txt",header=TRUE)
head(physical)
ale~Female, data = physical)
model1 <- lm(Male~Female, data = physical)
summary(model1)
cor(physical$Male, physical$Female)
cor(physical$RtFoot, physical$LeftFoot)
cor(physical$HeadCirc, physical$RtFoot)
cor(physical$HeadCirc, physical$LeftFoot)
cor(physical$HeadCirc, physical$Male)
model <- lm(HeadCirc ~ Male + Female, data = physical)
summary(model)
model2 <- lm(HeadCirc ~ RtFoot + Male, data = physical)
summary(model2)
model3 <- lm(HeadCirc ~ LeftFoot + RtFoot + Male, data = physical)
summary(model3)
anova(model3)
sqrt(198.472/50)
reduced_model <- lm(formula = HeadCirc ~ Male, data = physical)
anova(reduced_model, model3)
model4 <- lm(formula = HeadCirc ~ LeftFoot + RtFoot, data = physical)
summary(model4)
model5 <- lm(formula = HeadCirc ~ LeftFoot, data = physical)
summary(model5)
VIF(model4)
vif(model4)
library(car)
vif(model4)
vif(model3)
```{r}
model2 <- lm(bodymass~height + I(height^2), data = body)
summary(model2)
vif(model2)
MASS
library(MASS)
knitr::opts_chunk$set(echo = TRUE)
full = lm(Height ⇠ LeftArm + RtArm + LeftFoot + RtFoot + LeftHand + RtHand + HeadCirc + Nose + Male ,data = physical)
full = lm(Height ~ LeftArm + RtArm + LeftFoot + RtFoot + LeftHand + RtHand + HeadCirc + Nose + Male ,data = physical)
full = lm(Height ~ LeftArm + RtArm + LeftFoot + RtFoot + LeftHand + RtHand + HeadCirc + nose + Male ,data = physical)
step(lm(Height~1,data = physical), scope=list(upper=full), direction="forward")
full = lm(HeadCirc ~ Height + LeftArm + RtArm + LeftFoot + RtFoot + LeftHand + RtHand + nose + Male ,data = physical)
step(lm(HeadCirc ~ 1,data = physical), scope=list(upper=full), direction="forward")
best_model <- lm(formula = HeadCirc ~ Male + LeftHand, data = physical)
summary(best_model)
vif(model2)
library(car)
library(MASS)
vif(model2)
summary(regsubsets(HeadCirc ~ Height + LeftArm + RtArm + LeftFoot + RtFoot + LeftHand + RtHand + nose + Male, data = physical))
install.packages("leaps")
library(leaps)
summary(regsubsets(HeadCirc ~ Height + LeftArm + RtArm + LeftFoot + RtFoot + LeftHand + RtHand + nose + Male, data = physical))
cor(physical$Male, physical$Female)
cor(physical$RtFoot, physical$LeftFoot)
cor(physical$HeadCirc, physical$RtFoot)
cor(physical$HeadCirc, physical$LeftFoot)
cor(physical$HeadCirc, physical$Male)
cor(physical)
model2 <- lm(HeadCirc ~ RtFoot + Male, data = physical)
physical$hat = hatvalues(model2)
head(physical[order(physical$hat, decreasing=TRUE),])
summary(physical[physical$Male==1,])
head(physical[order(physical$hat, decreasing=TRUE),])
plot(physical$RtFoot, physical$HeadCirc, xlab="Right Foot size" , ylab="Head Circumference")
points(head(physical[order(physical$hat, decreasing=TRUE),])[1,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[1,"HeadCirc"], col="blue", cex=1.5 , pch=15)
plot(physical$RtFoot, physical$HeadCirc, xlab="Right Foot size" , ylab="Head Circumference")
points(head(physical[order(physical$hat, decreasing=TRUE),])[1,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[1,"HeadCirc"], col="blue", cex=1.5 , pch=15)
points(head(physical[order(physical$hat, decreasing=TRUE),])[2,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[2,"HeadCirc"], col="blue", cex=1.5 , pch=15)
plot(physical$RtFoot, physical$HeadCirc, xlab="Right Foot size" , ylab="Head Circumference")
points(head(physical[order(physical$hat, decreasing=TRUE),])[1,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[1,"HeadCirc"], col="blue", pch=15)
points(head(physical[order(physical$hat, decreasing=TRUE),])[2,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[2,"HeadCirc"], col="blue", cex=1.5 , pch=15)
plot(physical$RtFoot, physical$HeadCirc, xlab="Right Foot size" , ylab="Head Circumference")
points(head(physical[order(physical$hat, decreasing=TRUE),])[1,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[1,"HeadCirc"], col="blue")
points(head(physical[order(physical$hat, decreasing=TRUE),])[2,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[2,"HeadCirc"], col="blue")
plot(physical$RtFoot, physical$HeadCirc, xlab="Right Foot size" , ylab="Head Circumference")
points(head(physical[order(physical$hat, decreasing=TRUE),])[1,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[1,"HeadCirc"], col="blue", cex=1.5)
points(head(physical[order(physical$hat, decreasing=TRUE),])[2,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[2,"HeadCirc"], col="blue", cex=1.5)
plot(physical$RtFoot, physical$HeadCirc, xlab="Right Foot size" , ylab="Head Circumference")
points(head(physical[order(physical$hat, decreasing=TRUE),])[1,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[1,"HeadCirc"], col="blue", cex=1.5 , pch=10)
points(head(physical[order(physical$hat, decreasing=TRUE),])[2,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[2,"HeadCirc"], col="blue", cex=1.5 , pch=15)
plot(physical$RtFoot, physical$HeadCirc, xlab="Right Foot size" , ylab="Head Circumference")
points(head(physical[order(physical$hat, decreasing=TRUE),])[1,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[1,"HeadCirc"], col="blue", cex=1.5 , pch=21)
plot(physical$RtFoot, physical$HeadCirc, xlab="Right Foot size" , ylab="Head Circumference")
points(head(physical[order(physical$hat, decreasing=TRUE),])[1,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[1,"HeadCirc"], col="blue", cex=1.5 , pch=19)
points(head(physical[order(physical$hat, decreasing=TRUE),])[2,"RtFoot"], head(physical[order(physical$hat, decreasing=TRUE),])[2,"HeadCirc"], col="blue", cex=1.5 , pch=19)
physical$hat = hatvalues(model2)
head(physical[order(physical$hat, decreasing=TRUE),])
summary(physical)
head(physical[order(physical$hat, decreasing=TRUE),])
model2 <- lm(bodymass~height + I(height^2), data = body)
body$hat = hatvalues(model2)
head(body[order(body$hat, decreasing=TRUE),])
summary(body)
head(body[order(body$hat, decreasing=TRUE),])
model3 <- lm(HeadCirc ~ LeftFoot + RtFoot + Male, data = physical)
physical$hat = hatvalues(model3)
head(physical[order(physical$hat, decreasing=TRUE),])
summary(physical)
head(physical[order(physical$hat, decreasing=TRUE),])
knitr::opts_chunk$set(echo = TRUE)
cor(physical)
model4 <- lm(formula = HeadCirc ~ LeftFoot + RtFoot, data = physical)
summary(model4)
model6 <- lm(formula = HeadCirc ~ LeftFoot + hat, data = physical)
summary(model6)
VIF(model6)
vif(model6)
```{r}
library(car)
library(MASS)
library(leaps)
vif(model6)
vif(model4)
vif(model6)
model6 <- lm(formula = HeadCirc ~ LeftFoot + I(LeftFoot^2), data = physical)
summary(model6)
vif(model6)
model4 <- lm(formula = HeadCirc ~ LeftFoot + RtFoot, data = physical)
summary(model4)
model6 <- lm(formula = HeadCirc ~ 1, data = physical)
summary(model6)
anova(model6, model4)
library(tidyverse)
get_cooccurrence_tokens3 <- function(corpus, set1, set2) {
root_list <- c()
data = read.table(corpus, header = FALSE)[[1]]
for (root in data) {
for (element in set1) {
if(str_detect(root, element)) {
for (element in set2) {
if (str_detect(root, element)) {
if (!(root %in% root_list)) {
root_list <- append(root_list, root)
}
}
}
}
}
}
return(root_list)
}
get_cooccurrence_proportion <- function(corpus, set1, set2){
data = read_csv(corpus, col_names = FALSE)
num_of_roots = length(data$X1)
num_of_disharm_roots = length(get_cooccurrence_tokens2(corpus, set1, set2))
proportion = num_of_disharm_roots / num_of_roots
return(proportion)
}
Finnish_prop = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
get_cooccurrence_proportion <- function(corpus, set1, set2){
data = read_csv(corpus, col_names = FALSE)
num_of_roots = length(data$X1)
num_of_disharm_roots = length(get_cooccurrence_tokens(corpus, set1, set2))
proportion = num_of_disharm_roots / num_of_roots
return(proportion)
}
Finnish_prop = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
get_cooccurrence_proportion <- function(corpus, set1, set2){
data = read_csv(corpus, col_names = FALSE)
num_of_roots = length(data$X1)
num_of_disharm_roots = length(get_cooccurrence_tokens3(corpus, set1, set2))
proportion = num_of_disharm_roots / num_of_roots
return(proportion)
}
Finnish_prop = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/finnish.txt",
c("y", "ö", "ä"),
c("u", "o", "a"))
Uyghur_prop = get_cooccurrence_proportion("http://socsci.uci.edu/~cjmayer/teaching/LSCI_202A/uyghur.txt",
c("ü", "ö", "e"),
c("u", "o", "a"))
print(Finnish_prop)
print(Uyghur_prop)
install.packages("rstan", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
install.packages(c("dplyr","purrr","tidyr", "extraDistr", "brms","hypr","lme4")
d
install.packages(c("dplyr","purrr","tidyr", "extraDistr", "brms","hypr","lme4"))
install.packages(c("dplyr", "purrr", "tidyr", "extraDistr", "brms", "hypr", "lme4"))
remotes::install_github("bnicenboim/bcogsci")
extract <- rstan::extract
library(dplyr)
library(tidyr)
library(purrr)
library(extraDistr)
library(ggplot2)
library(loo)
library(bridgesampling)
library(brms)
library(bayesplot)
library(tictoc)
install.packages("tictoc")
library(tictoc)
# Lecture 1.2 exercises
probs<-round(dbinom(0:10, size = 10, prob = 0.5),3)
x <- 0:10
probs
# Lecture 1.2 exercises
probs<-round(dbinom(0:10, size = 10, prob = 0.1),3)
probs
round(pbinom(0:10, size = 10, prob = 0.15),3)
pnorm(-3)
pnorm(-3, lower.tail=FALSE)
data <- load_data("prob1312.csv")
library(tidyverse)
library(dplyr)
library(showtext)
showtext_auto()
library(lme4)
library(lmerTest)
library(ggplot2)
library(poolr)
load_data <- function(file) {
logprob <- read_delim(file, locale=locale(encoding="UTF-8"),
col_names = c("target_word",
"concept",
"word_form",
"target_word_logprob",
"disj_logprob",
"line_num"))
logprob$line_num <- as.factor(logprob$line_num)
logprob$word_form <- as.factor(logprob$word_form)
return(logprob)
}
data <- load_data("prob1312.csv")
data %>% group_by(target_word, concept, word_form) %>% summarize(disj_logprob=mean(disj_logprob), target_word_logprob=mean(target_word_logprob)) %>%
ungroup() %>% select(-target_word, -target_word_logprob) %>% spread(word_form, disj_logprob)
# means = data %>% group_by(target_word, concept, word_form) %>% summarize(disj_logprob=mean(disj_logprob), target_word_logprob=mean(target_word_logprob)) %>% ungroup()
# using this can directly change logprob to surprisal
means = data %>% group_by(target_word, concept, word_form) %>% summarize(concept_surprisal=-mean(disj_logprob), target_word_surprisal=-mean(target_word_logprob)) %>% ungroup()
t_test_data <- means %>% select(-target_word, -target_word_surprisal) %>% spread(word_form, concept_surprisal)
setwd("/Users/yanting/Desktop/word_length/scripts_and_texts")
data <- load_data("prob1312.csv")
data %>% group_by(target_word, concept, word_form) %>% summarize(disj_logprob=mean(disj_logprob), target_word_logprob=mean(target_word_logprob)) %>%
ungroup() %>% select(-target_word, -target_word_logprob) %>% spread(word_form, disj_logprob)
# means = data %>% group_by(target_word, concept, word_form) %>% summarize(disj_logprob=mean(disj_logprob), target_word_logprob=mean(target_word_logprob)) %>% ungroup()
# using this can directly change logprob to surprisal
means = data %>% group_by(target_word, concept, word_form) %>% summarize(concept_surprisal=-mean(disj_logprob), target_word_surprisal=-mean(target_word_logprob)) %>% ungroup()
t_test_data <- means %>% select(-target_word, -target_word_surprisal) %>% spread(word_form, concept_surprisal)
t.test(t_test_data$long, t_test_data$short, paired = TRUE)
disj <- data %>% select(-target_word, -target_word_logprob, -line_num) %>% mutate(surprisal = -disj_logprob) %>% mutate(is_short = ifelse(word_form == 'short', 0, 1))
disj$word_form <- as.factor(disj$word_form)
mixed_ml2 <- glmer(is_short ~ 1 + surprisal + (1 + surprisal|concept), data = disj, family = binomial)
summary(mixed_ml2)
pnorm(5, 3, 1)
pnorm(5, 3, 3)
pnorm(5, 3, 1, lower.tail = FALSE)
pnorm(5, 4, 3, lower.tail = FALSE)
pnorm(5, 3, 1) - pnorm(2, 3, 1)
pnorm(1.5, 3, 1) - pnorm(1, 3, 1)
pnorm(1.5) - pnorm(1)
round(dbinom(0:10, size = 15, prob = 0.5),3)
round(dbinom(0:15, size = 15, prob = 0.5),3)
round(dbinom(0:25, size = 25, prob = 0.25),3)
round(dbinom(0:10, size = 10, prob = 0.05),3)
round(dbinom(0:15, size = 15, prob = 0.75),3)
0.001+0.003+0.013+0.039+0.092+0.165+0.225+0.225
round(dbinom(0:15, size = 15, prob = 0.5),3)
0.003+0.014+0.042+0.092+0.153+0.196+0.196
+0.153
0.153+0.696
round(dbinom(0:55, size = 55, prob = 0.75),3)
0.001+0.003+0.006+0.011
0.021+0.019+0.032+0.05
0.122+0.071+0.093+0.111
0.397-0.111-0.093
qnorm(0.25)
qnorm(0.25, 1, 1)
qnorm(0.1, 1, 1)
round(dbinom(0:18, size = 18, prob = 0.65),3)
round(dbinom(0:18, size = 18, prob = 0.75),3)
round(dbinom(0:60, size = 60, prob = 0.1),3)
650-125
qnorm(0.1, 650, 125)
650-489.8061
160.1939+650
round(dbinom(0:15, size = 15, prob = 0.5),3)
0.003+0.014+0.042+0.092+0.153+0.196
pnorm(2, 0, 1, lower.tail=FALSE)
pnorm(-2.5)
round(pbinom(0:10, size = 10, prob = 0.5),3)
